{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "191e0442-3786-4e08-b9d1-8592cf3cfbe2",
   "metadata": {},
   "source": [
    "I first began my using the code from team member 2 to allow me to download and collate the respondant's answer files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f744b0b-c97c-4fa5-8ae5-005cae892e13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded: answers_respondent_1.txt\n",
      "Downloaded: answers_respondent_2.txt\n",
      "Downloaded: answers_respondent_3.txt\n",
      "Downloaded: answers_respondent_4.txt\n",
      "Downloaded: answers_respondent_5.txt\n",
      "Downloaded: answers_respondent_6.txt\n",
      "Downloaded: answers_respondent_7.txt\n",
      "Downloaded: answers_respondent_8.txt\n",
      "Downloaded: answers_respondent_9.txt\n",
      "Downloaded: answers_respondent_10.txt\n",
      "Downloaded: answers_respondent_11.txt\n",
      "Downloaded: answers_respondent_12.txt\n",
      "Downloaded: answers_respondent_13.txt\n",
      "Downloaded: answers_respondent_14.txt\n",
      "Downloaded: answers_respondent_15.txt\n",
      "Downloaded: answers_respondent_16.txt\n",
      "Downloaded: answers_respondent_17.txt\n",
      "Downloaded: answers_respondent_18.txt\n",
      "Downloaded: answers_respondent_19.txt\n",
      "Downloaded: answers_respondent_20.txt\n",
      "Downloaded: answers_respondent_21.txt\n",
      "Downloaded: answers_respondent_22.txt\n",
      "Downloaded: answers_respondent_23.txt\n",
      "Downloaded: answers_respondent_24.txt\n",
      "Downloaded: answers_respondent_25.txt\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from pathlib import Path\n",
    "import os \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def download_answer_files(cloud_url:str, path_to_data_folder: str, respondent_index:int):\n",
    "    data_folder= Path(path_to_data_folder)\n",
    "\n",
    "    if not data_folder.exists():\n",
    "        data_folder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    for i in range(1, respondent_index+1):\n",
    "        file_name= f\"answers_respondent_{i}.txt\"\n",
    "        file_url=f\"{cloud_url}/{file_name}?raw=true\"\n",
    "        local_name = os.path.join(path_to_data_folder, file_name)\n",
    "        try:\n",
    "                    response = requests.get(file_url)\n",
    "                    response.raise_for_status()\n",
    "                    with open(local_name, \"w\", encoding=\"utf-8\") as file:\n",
    "                        file.write(response.text)\n",
    "                    print(f\"Downloaded: {file_name}\")\n",
    "        except requests.RequestException as e:\n",
    "            print(f\"Failed to download {file_name}: {e}\")\n",
    "          \n",
    "download_answer_files(\n",
    "    cloud_url=\"https://github.com/tdvl3720-uol/Group-Project---Alan-Turing/raw/main/data\",\n",
    "    path_to_data_folder=\"data\",\n",
    "    respondent_index=25)\n",
    "\n",
    "def collate_answer_files(data_folder_path):\n",
    "    output_folder = \"output\"\n",
    "    output_file_path = os.path.join(output_folder, \"collated_answers.txt\")\n",
    "    \n",
    "    \n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "    \n",
    "    files = sorted(os.listdir(data_folder_path))\n",
    "    \n",
    "    with open(output_file_path, 'w', encoding='utf-8') as outfile:\n",
    "        for filename in files:\n",
    "            file_path = os.path.join(data_folder_path, filename)\n",
    "            with open(file_path, 'r', encoding='utf-8') as infile:\n",
    "                content = infile.read()\n",
    "                outfile.write(content)\n",
    "                outfile.write(\"\\n*\\n\")  \n",
    "    print(f\"Collated answers saved to {output_file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f6c081-c630-4537-b124-746fe4790d8d",
   "metadata": {},
   "source": [
    "Then, using the extract_answer_sequence from team member 1, I was able to extract sequences from each file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34e93f82-d856-48e1-9cef-b0ce45619527",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_answers_sequence(file_path):\n",
    "    answers = []\n",
    "    with open(file_path, \"r\") as file:\n",
    "        lines = [line.strip() for line in file.readlines() if line.strip() != \"\"]\n",
    "\n",
    "    for i in range(0, len(lines), 5):\n",
    "        question_block = lines[i:i+5]\n",
    "        selected = 0\n",
    "        for j in range(1, 5):\n",
    "            if \"[x]\" in question_block[j]:\n",
    "                selected = j\n",
    "        answers.append(selected)\n",
    "\n",
    "    return answers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff8cd3f8-9a1c-4640-ac53-cb4eff2a7a55",
   "metadata": {},
   "source": [
    "Then, leveraging the code from team member 3, I was able to run an analysis on the respondant's answers, and plotted graphs to help visualise any patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa6c4af1-67c7-4c2a-b316-30f1a1e16651",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'output/collated_answers.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 22\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m means\n\u001b[1;32m     21\u001b[0m collated_answers_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput/collated_answers.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 22\u001b[0m means \u001b[38;5;241m=\u001b[39m (\u001b[43mgenerate_means_sequence\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcollated_answers_path\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(means)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvisualize_data\u001b[39m(collated_answers_path, n):\n",
      "Cell \u001b[0;32mIn[7], line 3\u001b[0m, in \u001b[0;36mgenerate_means_sequence\u001b[0;34m(collated_answers_path)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_means_sequence\u001b[39m(collated_answers_path):\n\u001b[0;32m----> 3\u001b[0m     answers \u001b[38;5;241m=\u001b[39m \u001b[43mextract_answers_sequence\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moutput/collated_answers.txt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m     means \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      5\u001b[0m     num_questions \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m\n",
      "Cell \u001b[0;32mIn[6], line 3\u001b[0m, in \u001b[0;36mextract_answers_sequence\u001b[0;34m(file_path)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mextract_answers_sequence\u001b[39m(file_path):\n\u001b[1;32m      2\u001b[0m     answers \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m----> 3\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[1;32m      4\u001b[0m         lines \u001b[38;5;241m=\u001b[39m [line\u001b[38;5;241m.\u001b[39mstrip() \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m file\u001b[38;5;241m.\u001b[39mreadlines() \u001b[38;5;28;01mif\u001b[39;00m line\u001b[38;5;241m.\u001b[39mstrip() \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(lines), \u001b[38;5;241m5\u001b[39m):\n",
      "File \u001b[0;32m/home/sage/sage/local/var/lib/sage/venv-python3.11.1/lib/python3.11/site-packages/IPython/core/interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    322\u001b[0m     )\n\u001b[0;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'output/collated_answers.txt'"
     ]
    }
   ],
   "source": [
    "def generate_means_sequence(collated_answers_path):\n",
    "\n",
    "    answers = extract_answers_sequence(\"output/collated_answers.txt\")\n",
    "    means = []\n",
    "    num_questions = 100\n",
    "    num_respondents = len(answers)//num_questions\n",
    "    for i in range(num_questions):\n",
    "        total = 0\n",
    "        count = 0\n",
    "\n",
    "        for j in range(num_respondents):\n",
    "            index = j * num_questions + i\n",
    "            value = answers[index]\n",
    "            if value != 0:\n",
    "                total += value\n",
    "                count += 1\n",
    "        mean = total / count if count > 0 else 0\n",
    "        means.append(mean)\n",
    "    return means\n",
    "\n",
    "collated_answers_path = \"output/collated_answers.txt\"\n",
    "means = (generate_means_sequence(collated_answers_path))\n",
    "print(means)\n",
    "\n",
    "def visualize_data(collated_answers_path, n):\n",
    "\n",
    "    plt.close(\"all\")\n",
    "  \n",
    "    if n==1:\n",
    "        x = list(range(1, 101))\n",
    "        y = means\n",
    "        plt.scatter(x, y, s=15, marker = '.')\n",
    "        plt.xlabel(\"Question number\")\n",
    "        plt.ylabel(\"Mean value\")\n",
    "        plt.title(\"Means sequence\")\n",
    "        plt.show()\n",
    "\n",
    "    elif n==2:\n",
    "        base_url = \"https://raw.githubusercontent.com/tdvl3720-uol/Group-Project---Alan-Turing/main/data/\"\n",
    "        file_names = [f\"answers_respondent_{i}.txt\" for i in range(1, 26)]\n",
    "        respondent_answers = []\n",
    "\n",
    "        for file_name in file_names:\n",
    "            url = base_url + file_name\n",
    "            response = requests.get(url)\n",
    "            if response.status_code == 200:\n",
    "                lines = response.text.splitlines()\n",
    "                answers = []\n",
    "                \n",
    "                for i in range(100):  \n",
    "                    question_answers = lines[i * 4: (i + 1) * 4]  \n",
    "                    answer = 0\n",
    "                    \n",
    "                    for option in question_answers:\n",
    "                        if \"[x]\" in option:\n",
    "                            answer = 1  \n",
    "                            break\n",
    "                            \n",
    "                    answers.append(answer)\n",
    "                respondent_answers.append(answers)  \n",
    "            else:\n",
    "                print(f\"Failed to load {file_name}\")\n",
    "\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        for i, answers in enumerate(respondent_answers):\n",
    "            plt.plot(range(1,101), answers, label = f'Respondent_{i+1}')\n",
    "            plt.xlabel(\"Question numbers\")\n",
    "            plt.ylabel(\"Answered(1) / Not Answered(0)\")\n",
    "            plt.title(\"Individual Answers\")\n",
    "            plt.legend(loc='center left', bbox_to_anchor=(1, 0.5), title=\"Respondents\")\n",
    "            plt.xticks(np.arange(0, 101, 10))\n",
    "            plt.show()\n",
    "            \n",
    "\n",
    "    else:\n",
    "        print(\"error: n!=1, n!=2\")\n",
    "\n",
    "visualize_data(collated_answers_path, 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d558c41a-d977-4455-848f-eb2c4f3a907c",
   "metadata": {},
   "source": [
    "From the mean sequence plot, we can see that a lot of the dots lie around the 2.46 to 2.63 range, suggesting that most answers put down were the second or third option. Some dots stand out , with the dots around the 16 - 17th question being close to the value of 2, suggesting that majority answers put down on those questions were option 2. The same with the dot around the the 77th question, with it being close to 2.1, suggeting that majoirty also answered option 2 for that question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0568282c-0813-46cd-81e8-1bfdf207000b",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_data(collated_answers_path, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47304a08-b758-40c3-9720-3a4d7594bdb0",
   "metadata": {},
   "source": [
    "From the response graphs of each indivdual respondant, we can see that between 40-50, many seem to have attempted to answer those questions. Similarly, between question 90-94/95 question, respondants seem to have answered those questions as well. There also similar patterns like this, but majority of the questions have not been answered, compared to has been answered."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
