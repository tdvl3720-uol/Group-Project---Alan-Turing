{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is a review of the 'data_preperation_M2.py' script which I wrote in order to evaluate the structure, functionality and identify any patterns within the data from the python quiz. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, I imported the neccessary libraries: requests, Path and os. I used requests in order to get the python quiz data and save it locally, I did through using a url link to our GitHub data folder. In addition, Path converts the string 'data' into a Path object which makes easier to deal with. Lastly, I used the library os to join folders to create the collare answers file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from pathlib import Path\n",
    "import os "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I then wrote the function 'def download_answer_files'. This function changes the text files format from a1. txt etc to answers_respondent_1.txt - answers_respondent_n.txt, through a for loop and saves them to the data folder. Where n= 25 because 25 people answered the python quiz. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded: answers_respondent_1.txt\n",
      "Downloaded: answers_respondent_2.txt\n",
      "Downloaded: answers_respondent_3.txt\n",
      "Downloaded: answers_respondent_4.txt\n",
      "Downloaded: answers_respondent_5.txt\n",
      "Downloaded: answers_respondent_6.txt\n",
      "Downloaded: answers_respondent_7.txt\n",
      "Downloaded: answers_respondent_8.txt\n",
      "Downloaded: answers_respondent_9.txt\n",
      "Downloaded: answers_respondent_10.txt\n",
      "Downloaded: answers_respondent_11.txt\n",
      "Downloaded: answers_respondent_12.txt\n",
      "Downloaded: answers_respondent_13.txt\n",
      "Downloaded: answers_respondent_14.txt\n",
      "Downloaded: answers_respondent_15.txt\n",
      "Downloaded: answers_respondent_16.txt\n",
      "Downloaded: answers_respondent_17.txt\n",
      "Downloaded: answers_respondent_18.txt\n",
      "Downloaded: answers_respondent_19.txt\n",
      "Downloaded: answers_respondent_20.txt\n",
      "Downloaded: answers_respondent_21.txt\n",
      "Downloaded: answers_respondent_22.txt\n",
      "Downloaded: answers_respondent_23.txt\n",
      "Downloaded: answers_respondent_24.txt\n",
      "Downloaded: answers_respondent_25.txt\n"
     ]
    }
   ],
   "source": [
    "def download_answer_files(cloud_url:str, path_to_data_folder: str, respondent_index:int):\n",
    "   os.makedirs(path_to_data_folder, exist_ok=True)\n",
    "   for i in range(1, respondent_index+1):\n",
    "        file_name= f\"answers_respondent_{i}.txt\"\n",
    "        file_url=f\"{cloud_url}/{file_name}?raw=true\"\n",
    "        local_name = os.path.join(path_to_data_folder, file_name)\n",
    "        try:\n",
    "                    response = requests.get(file_url)\n",
    "                    response.raise_for_status()\n",
    "                    with open(local_name, \"w\", encoding=\"utf-8\") as file:\n",
    "                        file.write(response.text)\n",
    "                    print(f\"Downloaded: {file_name}\")\n",
    "        except requests.RequestException as e:\n",
    "            print(f\"Failed to download {file_name}: {e}\")\n",
    "          \n",
    "download_answer_files(\n",
    "    cloud_url=\"https://github.com/tdvl3720-uol/Group-Project---Alan-Turing/raw/main/data\",\n",
    "    path_to_data_folder=\"data\",\n",
    "    respondent_index=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Furthermore, I wrote the function 'def collate_answer_files', the purpose of this function is to read all the downloaded answer files and combine them into one single file called 'collated_answers.txt'. In order to do this, I made sure the output folder existed, which is where the collated file will be saved. Then I listed and sorted all the files in numerical order ie. from 1-25. Finally, I wrote a for loop which iterates over every .txt file, reads it, writes the content into the output file and then adds a '*' between each file in order to to be able to differentiate between each answer file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_answer_files(data_folder_path):\n",
    "    output_file_path=\"output/collated_answers.txt\"\n",
    "    \n",
    "    files = sorted(os.listdir(data_folder_path))\n",
    "    \n",
    "    with open(output_file_path, 'w', encoding='utf-8') as outfile:\n",
    "        for filename in files:\n",
    "            file_path = os.path.join(data_folder_path, filename)\n",
    "            with open(file_path, 'r', encoding='utf-8') as infile:\n",
    "                content = infile.read()\n",
    "                outfile.write(content)\n",
    "                outfile.write(\"\\n*\\n\")  \n",
    "    print(f\"Collated answers saved to {output_file_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
