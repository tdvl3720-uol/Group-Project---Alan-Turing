{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is a review of the 'data_preperation_M2.py' script which I wrote in order to evaluate the structure, functionality and identify any patterns within the data from the python quiz. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, I imported the neccessary libraries: requests, Path and os. I used requests in order to get the python quiz data and save it locally, I did through using a url link to our GitHub data folder. In addition, Path converts the string 'data' into a Path object which makes easier to deal with. Lastly, I used the library os to join folders to create the collare answers file. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I then wrote the function 'def download_answer_files'. This function changes the text files format from a1. txt etc to answers_respondent_1.txt - answers_respondent_n.txt, through a for loop and saves them to the data folder. Where n= 25 because 25 people answered the python quiz. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Furthermore, I wrote the function 'def collate_answer_files', the purpose of this function is to read all the downloaded answer files and combine them into one single file called 'collated_answers.txt'. In order to do this, I made sure the output folder existed, which is where the collated file will be saved. Then I listed and sorted all the files in numerical order ie. from 1-25. Finally, I wrote a for loop which iterates over every .txt file, reads it, writes the content into the output file and then adds a '*' between each file in order to to be able to differentiate between each answer file. "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
